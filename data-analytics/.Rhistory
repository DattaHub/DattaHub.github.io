auto.assign = FALSE,
return.class = 'ts'))
stockmat <- cbind(stockmat, stockvalues[,4])
}
stockmat <- NULL
for(i in 1:80){
stockvalues <- as.matrix(getSymbols(str[i],
from = "2012/12/31",
to = "2018/12/31",
periodicity = "monthly",
src = "yahoo",
auto.assign = FALSE,
return.class = 'ts'))
stockmat <- cbind(stockmat, stockvalues[,4])
}
%%
rm(list =ls())
yahoo <- read.csv("NYSENasdaqConsumerDefensive.csv")
str <- yahoo[,1]
stockmat <- NULL
for(i in 1:70){
stockvalues <- as.matrix(getSymbols(str[i],
from = "2012/12/31",
to = "2018/12/31",
periodicity = "monthly",
src = "yahoo",
auto.assign = FALSE,
return.class = 'ts'))
stockmat <- cbind(stockmat, stockvalues[,4])
}
%%
rm(list =ls())
yahoo <- read.csv("NYSENasdaqConsumerDefensive.csv")
str <- yahoo[,1]
stockmat <- NULL
for(i in 1:50){
stockvalues <- as.matrix(getSymbols(str[i],
from = "2012/12/31",
to = "2018/12/31",
periodicity = "monthly",
src = "yahoo",
auto.assign = FALSE,
return.class = 'ts'))
stockmat <- cbind(stockmat, stockvalues[,4])
}
str<-c('PG', 'AAPL','WMT','KO')
stockName <- NULL
for(i in 1:4){
stockName <- getSymbols(str[i],
from = "2016/12/31",
to = "2018/12/31",
periodicity = "monthly",
auto.assign = FALSE,
return.class = 'ts')
stockName
}
%%
rm(list =ls())
gc()
yahoo <- read.csv("NYSENasdaqConsumerDefensive.csv")
str <- yahoo[,1]
stockmat <- NULL
for(i in 1:50){
stockvalues <- as.matrix(getSymbols(str[i],
from = "2012/12/31",
to = "2018/12/31",
periodicity = "monthly",
src = "yahoo",
auto.assign = FALSE,
return.class = 'ts'))
stockmat <- cbind(stockmat, stockvalues[,4])
}
colnames(stockmat) <- str[1:50]
head(stockmat)
whole_dataframe %>% pivot_wider(names_from = str, values_from = Volume)
library(SP500R)
whole_dataframe <- all_stocks()
SP500_names()
library(tidyverse)
whole_dataframe %>% pivot_wider(names_from = str, values_from = Volume)
setwd("~/Course Notes/data_analytics/older/da/lectures/lect6")
options(width=80)
library(knitr)
knit_hooks$set(no.main = function(before, options, envir) {
if (before) par(mar = c(4.1, 4.1, 1.1, 1.1))  # smaller margin on top
})
census <- read.csv("census2000.csv")
workers <- census$income > 1000
log.wrate <- log(census$income/census$hours)[workers]
edu <- census$education[workers]
levels(edu)
edu
str(census)
census <- read.csv("census2000.csv",stringsAsFactors = TRUE)
workers <- census$income > 1000
log.wrate <- log(census$income/census$hours)[workers]
edu <- census$education[workers]
levels(edu)
plot(edu, log.wrate, col=7, xlab="education", ylab="log Hourly Rate")
download.file("http://stat.duke.edu/~cr173/Sta102_Sp14/Project/heart.Rdata",
destfile = "heart.Rdata")
load("heart.Rdata")
getwd()
rm(list = ls())
setwd("~/Course Notes/data_analytics/master/R codes")
load("datasets/heart.Rdata")
load("datasets/heart.RData")
read.csv("https://hastie.su.domains/ElemStatLearn/datasets/SAheart.data")
rm(list = ls())
sahd <- read.csv("https://hastie.su.domains/ElemStatLearn/datasets/SAheart.data")
str(sahd)
sahd <- read.csv("https://hastie.su.domains/ElemStatLearn/datasets/SAheart.data",
stringsAsFactors = T, row.names = 1)
str(sahd)
knitr::opts_chunk$set(echo = TRUE)
pairs(sahd[,-5])
pairs(sahd[,-5], col  = chd)
pairs(sahd[,-5], col  = sahd$chd)
pairs(sahd[,-c(5,10)], col  = sahd$chd)
pairs(sahd[,-c(5,10)], col  = 1+sahd$chd)
pairs(sahd[,-c(5,10)], col  = 2+sahd$chd)
glm.fits=glm(chd~.,data=sahd,family=binomial)
summary(glm.fits)
knitr::opts_chunk$set(echo = TRUE)
glm.fits=glm(chd~.,data=sahd,family=binomial)
summary(glm.fits)
setwd("~/GitHub/DattaHub.github.io/data-analytics")
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
load("bc-tcga.Rdata")
setwd("~/GitHub/DattaHub.github.io/data-analytics")
load("bc-tcga.Rdata")
load("bc-tcga.rds")
if(!require(glmnet)){
install.packages("glmnet", dependencies = TRUE, repos = 'http://cran.rstudio.com')
}
library(MASS)  # Package needed to generate correlated precictors
library(glmnet)
set.seed(1234)
n <- 100    # Number of observations
p <- 50     # Number of predictors included in model
p1 <- 10 # Number of non-zero beta'
rho = 0.7
CovMatrix <- outer(1:p, 1:p, function(x,y) {rho^abs(x-y)})
x <- mvrnorm(n, rep(0,p), CovMatrix)
beta <- c(rep(5,p1),rep(0,p-p1))
eps=rnorm(n,mean=0,sd=0.1)
fx = x %*% beta
y=fx+eps
library(reshape)
simple_heatmap <- function(x){
melted_x <- melt(x)
min_x = min(x)
mid_x = mean(x)
max_x = max(x)
head(melted_x)
library(ggplot2)
p = ggplot(data = melted_x, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "grey")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = mid_x, limit = c(min_x, max_x), space = "Lab",
name="Scale") +
theme_light()+
# theme(axis.text.x = element_text(angle = 45, vjust = 1,
#                                  size = 12, hjust = 1))+
theme(axis.text.x = element_blank())+
coord_fixed()
return(p)
}
simple_heatmap(cov(x))
library(reshape2)
simple_heatmap <- function(x){
melted_x <- melt(x)
min_x = min(x)
mid_x = mean(x)
max_x = max(x)
head(melted_x)
library(ggplot2)
p = ggplot(data = melted_x, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "grey")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = mid_x, limit = c(min_x, max_x), space = "Lab",
name="Scale") +
theme_light()+
# theme(axis.text.x = element_text(angle = 45, vjust = 1,
#                                  size = 12, hjust = 1))+
theme(axis.text.x = element_blank())+
coord_fixed()
return(p)
}
simple_heatmap(cov(x))
library(reshape2)
simple_heatmap <- function(x){
melted_x <- melt(x)
min_x = min(x)
mid_x = mean(x)
max_x = max(x)
head(melted_x)
library(ggplot2)
p = ggplot(data = melted_x, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "grey")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = mid_x, limit = c(min_x, max_x), space = "Lab",
name="Scale") +
theme_light()+
# theme(axis.text.x = element_text(angle = 45, vjust = 1,
#                                  size = 12, hjust = 1))+
theme(axis.text.x = element_blank())+
coord_fixed()
return(p)
}
simple_heatmap(cor(x))
library(reshape2)
simple_heatmap <- function(x){
melted_x <- melt(x)
min_x = min(x)
mid_x = mean(x)
max_x = max(x)
head(melted_x)
library(ggplot2)
p = ggplot(data = melted_x, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "grey")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = mid_x, limit = c(min_x, max_x), space = "Lab",
name="Scale") +
theme_light()+
# theme(axis.text.x = element_text(angle = 45, vjust = 1,
#                                  size = 12, hjust = 1))+
theme(axis.text.x = element_blank())+
coord_fixed()
return(p)
}
simple_heatmap(CovMatrix)
knitr::opts_chunk$set(echo = TRUE)
library(MASS)  # Package needed to generate correlated precictors
library(glmnet)
set.seed(1234)
n <- 100    # Number of observations
p <- 50     # Number of predictors included in model
p1 <- 10 # Number of non-zero beta'
rho = 0
rho.set = c(0,0.3,0.5,0.9)
alpha.set = seq(0,1,length.out=11)
printf <- function(...) invisible(print(sprintf(...)))
mse.table = matrix(0,length(rho.set),length(alpha.set))
nonzero.table = matrix(0,length(rho.set),length(alpha.set))
for (i in 1:length(rho.set)){
for (j in 1:length(alpha.set)){
r = rho.set[i]
a = alpha.set[j]
CovMatrix <- outer(1:p, 1:p, function(x,y) {r^abs(x-y)})
x <- mvrnorm(n, rep(0,p), CovMatrix)
beta <- c(rep(5,p1),rep(0,p-p1))
eps=rnorm(n,mean=0,sd=0.1)
fx = x %*% beta
y=fx+eps
# Split data into train and test sets
train_rows <- sample(1:n, n/2)
x.train <- x[train_rows, ]
x.test <- x[-train_rows, ]
y.train <- y[train_rows]
y.test <- y[-train_rows]
fit <- cv.glmnet(x.train, y.train, type.measure="mse",alpha=a)
yhat <- predict(fit, s=fit$lambda.1se, newx=x.test)
mse <- mean((y.test - yhat)^2)
mse.table[i,j] = mse
coeff <- coef.cv.glmnet(fit, s =fit$lambda.1se )
nonzero.table[i,j] = length(coeff[which(coeff!=0)])
#printf("For correlation %f MSE for GLMNET with alpha = %f is %f", r, a, mse)
}
}
fit.enet <- cv.glmnet(x.train, y.train, type.measure = "mse",alpha=.5)
plot(fit.enet)
yhat.enet <- predict(fit.enet, s=fit.enet$lambda.1se, newx=x.test)
fit.lasso <- cv.glmnet(x.train, y.train, type.measure = "mse",alpha=1)
plot(fit.lasso)
yhat.lasso <- predict(fit.lasso, s=fit.lasso$lambda.1se, newx=x.test)
(mse.enet <- mean((y.test - yhat.enet)^2))
(mse.lasso <- mean((y.test - yhat.lasso)^2))
library(MASS)  # Package needed to generate correlated precictors
library(glmnet)
set.seed(1234)
n <- 100    # Number of observations
p <- 50     # Number of predictors included in model
p1 <- 10 # Number of non-zero beta'
rho = 0
rho.set = c(0,0.3,0.5,0.9)
alpha.set = seq(0,1,length.out=11)
printf <- function(...) invisible(print(sprintf(...)))
mse.table = matrix(0,length(rho.set),length(alpha.set))
nonzero.table = matrix(0,length(rho.set),length(alpha.set))
for (i in 1:length(rho.set)){
for (j in 1:length(alpha.set)){
r = rho.set[i]
a = alpha.set[j]
CovMatrix <- outer(1:p, 1:p, function(x,y) {r^abs(x-y)})
x <- mvrnorm(n, rep(0,p), CovMatrix)
beta <- c(rep(5,p1),rep(0,p-p1))
eps=rnorm(n,mean=0,sd=0.1)
fx = x %*% beta
y=fx+eps
# Split data into train and test sets
train_rows <- sample(1:n, n/2)
x.train <- x[train_rows, ]
x.test <- x[-train_rows, ]
y.train <- y[train_rows]
y.test <- y[-train_rows]
fit <- cv.glmnet(x.train, y.train, type.measure="mse",alpha=a)
yhat <- predict(fit, s=fit$lambda.1se, newx=x.test)
mse <- mean((y.test - yhat)^2)
mse.table[i,j] = mse
coeff <- coef(fit, type = "coefficient", s = fit$lambda.1se)
nonzero.table[i,j] = length(coeff[which(coeff!=0)])
#printf("For correlation %f MSE for GLMNET with alpha = %f is %f", r, a, mse)
}
}
library(MASS)  # Package needed to generate correlated precictors
library(glmnet)
set.seed(1234)
n <- 100    # Number of observations
p <- 50     # Number of predictors included in model
p1 <- 10 # Number of non-zero beta'
rho = 0
rho.set = c(0,0.3,0.5,0.9)
alpha.set = seq(0,1,length.out=11)
printf <- function(...) invisible(print(sprintf(...)))
mse.table = matrix(0,length(rho.set),length(alpha.set))
for (i in 1:length(rho.set)){
for (j in 1:length(alpha.set)){
r = rho.set[i]
a = alpha.set[j]
CovMatrix <- outer(1:p, 1:p, function(x,y) {r^abs(x-y)})
x <- mvrnorm(n, rep(0,p), CovMatrix)
beta <- c(rep(5,p1),rep(0,p-p1))
eps=rnorm(n,mean=0,sd=0.1)
fx = x %*% beta
y=fx+eps
# Split data into train and test sets
train_rows <- sample(1:n, n/2)
x.train <- x[train_rows, ]
x.test <- x[-train_rows, ]
y.train <- y[train_rows]
y.test <- y[-train_rows]
fit <- cv.glmnet(x.train, y.train, type.measure="mse",alpha=a)
yhat <- predict(fit, s=fit$lambda.1se, newx=x.test)
mse <- mean((y.test - yhat)^2)
mse.table[i,j] = mse
printf("For correlation %f MSE for GLMENT with alpha = %f is %f", r, a, mse)
}
}
library(ggplot2)
mse.data = rbind(data.frame(values=mse.table[1,], x=alpha.set, rho = rho.set[1]),
data.frame(values=mse.table[2,], x=alpha.set, rho = rho.set[2]),
data.frame(values=mse.table[3,], x=alpha.set, rho = rho.set[3]))
mse.plot = ggplot(mse.data, aes(x=x, y=values, group=as.factor(rho),
colour= as.factor(rho) )) +
geom_line() + ylab("M. S. E.") + xlab(expression(alpha))+scale_y_log10()
mse.plot <- mse.plot + theme(axis.title.y = element_text(size = rel(1.2), angle = 90))+theme(axis.title.x = element_text(size = rel(1.2)))
mse.plot<- mse.plot+ theme(axis.text = element_text(size = rel(1.2)))+
theme(legend.position = c(0.75,0.75),legend.title=element_text(size=15, face="bold"),legend.text=element_text(size=15))
mse.plot <- mse.plot+theme(strip.text.x = element_text(size=20, face="bold"),strip.text.y = element_text(size=15, face="bold"))
print(mse.plot)
mse.plot = ggplot(mse.data, aes(x=x, y=values, group=as.factor(rho),
colour= as.factor(rho) )) +
geom_line() + ylab("M. S. E.") + xlab(expression(alpha))+scale_y_log10()+theme_bw()
mse.plot <- mse.plot + theme(axis.title.y = element_text(size = rel(1.2), angle = 90))+theme(axis.title.x = element_text(size = rel(1.2)))
mse.plot<- mse.plot+ theme(axis.text = element_text(size = rel(1.2)))+
theme(legend.position = c(0.75,0.75),legend.title=element_text(size=15, face="bold"),legend.text=element_text(size=15))
mse.plot <- mse.plot+theme(strip.text.x = element_text(size=20, face="bold"),strip.text.y = element_text(size=15, face="bold"))
print(mse.plot)
library(MASS)  # Package needed to generate correlated precictors
library(MASS)  # Package needed to generate correlated precictors
library(glmnet)
set.seed(1234)
n <- 100    # Number of observations
p <- 50     # Number of predictors included in model
p1 <- 10 # Number of non-zero beta'
rho = 0
rho.set = c(0,0.3,0.5,0.9)
alpha.set = seq(0,1,length.out=11)
alpha.set
printf <- function(...) invisible(print(sprintf(...)))
mse.table = matrix(0,length(rho.set),length(alpha.set))
for (i in 1:length(rho.set)){
for (j in 1:length(alpha.set)){
r = rho.set[i]
a = alpha.set[j]
CovMatrix <- outer(1:p, 1:p, function(x,y) {r^abs(x-y)})
x <- mvrnorm(n, rep(0,p), CovMatrix)
beta <- c(rep(5,p1),rep(0,p-p1))
eps=rnorm(n,mean=0,sd=0.1)
fx = x %*% beta
y=fx+eps
# Split data into train and test sets
train_rows <- sample(1:n, n/2)
x.train <- x[train_rows, ]
x.test <- x[-train_rows, ]
y.train <- y[train_rows]
y.test <- y[-train_rows]
fit <- cv.glmnet(x.train, y.train, type.measure="mse",alpha=a)
yhat <- predict(fit, s=fit$lambda.1se, newx=x.test)
mse <- mean((y.test - yhat)^2)
mse.table[i,j] = mse
printf("For correlation %f MSE for GLMENT with alpha = %f is %f", r, a, mse)
}
}
library(ggplot2)
mse.data = rbind(data.frame(values=mse.table[1,], x=alpha.set, rho = rho.set[1]),
data.frame(values=mse.table[2,], x=alpha.set, rho = rho.set[2]),
data.frame(values=mse.table[3,], x=alpha.set, rho = rho.set[3]))
mse.plot = ggplot(mse.data, aes(x=x, y=values, group=as.factor(rho),
colour= as.factor(rho) )) +
geom_line() + ylab("M. S. E.") + xlab(expression(alpha))+scale_y_log10()+theme_bw()
mse.plot <- mse.plot + theme(axis.title.y = element_text(size = rel(1.2), angle = 90))+theme(axis.title.x = element_text(size = rel(1.2)))
mse.plot<- mse.plot+ theme(axis.text = element_text(size = rel(1.2)))+
theme(legend.position = c(0.75,0.75),legend.title=element_text(size=15, face="bold"),legend.text=element_text(size=15))
mse.plot <- mse.plot+theme(strip.text.x = element_text(size=20, face="bold"),strip.text.y = element_text(size=15, face="bold"))
print(mse.plot)
source("~/Course Notes/data_analytics/master/HW/subs/070722InClass1_Youmans.R")
knitr::opts_chunk$set(echo = TRUE, comment= ' ',warning=FALSE, message=FALSE, fig.show='asis',results='markup', fig.width=6.5, fig.height=3.5, fig.align='center',  linewidth=60, tidy=TRUE, tidy.opts=list(width.cutoff=60))
local({r <- getOption("repos"); r["CRAN"] <- "http://R.research.att.com"; options(repos=r)})
set.seed(1)
x <- rcauchy(n = 21)
B = 1e5
theta.boot = rep(0, B)
n = length(x)
for (b in 1:B) theta.boot[b] = median(sample(x, replace = TRUE))
var(theta.boot)
set.seed(1)
x <- rcauchy(n = 21)
B.set = 1e4*seq(10, 100, length.out = 11)
vboot = numeric(length(B.set))
for(i in length(B.set)){
B = B.set[i]
theta.boot = rep(0, B)
n = length(x)
for (b in 1:B) theta.boot[b] = median(sample(x, replace = TRUE))
vboot[i] = var(theta.boot)
}
plot(B.set, vboot)
plot(B.set, vboot)
vboot
set.seed(1)
x <- rcauchy(n = 21)
B.set = 1e3*seq(10, 100, length.out = 6)
vboot = numeric(length(B.set))
for(i in length(B.set)){
B = B.set[i]
theta.boot = rep(0, B)
n = length(x)
for (b in 1:B) theta.boot[b] = median(sample(x, replace = TRUE))
vboot[i] = var(theta.boot)
}
plot(B.set, vboot)
vboot
set.seed(1)
x <- rcauchy(n = 21)
B.set = 1e3*seq(10, 100, length.out = 6)
vboot = numeric(length(B.set))
B.set
for(i in length(B.set)){
B = B.set[i]
theta.boot = rep(0, B)
for (b in 1:B){
theta.boot[b] = median(sample(x, replace = TRUE))
}
vboot[i] = var(theta.boot)
}
vboot
theta.boot
set.seed(1)
x <- rcauchy(n = 21)
B = 2000
theta.boot = rep(0, B)
n = length(x)
for (b in 1:B) theta.boot[b] = median(sample(x, replace = TRUE))
var(theta.boot)
set.seed(1)
x <- rcauchy(n = 21)
B = 5000
theta.boot = rep(0, B)
n = length(x)
for (b in 1:B) theta.boot[b] = median(sample(x, replace = TRUE))
var(theta.boot)
set.seed(1)
x <- rcauchy(n = 21)
B = 1e4
theta.boot = rep(0, B)
n = length(x)
for (b in 1:B) theta.boot[b] = median(sample(x, replace = TRUE))
var(theta.boot)
set.seed(1)
x <- rcauchy(n = 21)
B = 2*1e4
theta.boot = rep(0, B)
n = length(x)
for (b in 1:B) theta.boot[b] = median(sample(x, replace = TRUE))
var(theta.boot)
set.seed(1)
x <- rcauchy(n = 21)
B.set = 1e3*seq(5, 10, by = 1)
vboot = numeric(length(B.set))
B.set
for(i in 1:length(B.set)){
B = B.set[i]
theta.boot = rep(0, B)
for (b in 1:B){
theta.boot[b] = median(sample(x, replace = TRUE))
}
vboot[i] = var(theta.boot)
}
plot(B.set, vboot)
vboot
