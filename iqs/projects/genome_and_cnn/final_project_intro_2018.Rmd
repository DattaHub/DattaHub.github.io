---
title: "Project Ideas"
author: "Jyotishka Datta"
date: "October 31, 2019"
output: 
  ioslides_presentation:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE)
```

<style>
  .col2 {
    columns: 2 200px;         /* number of columns and width in pixels*/
    -webkit-columns: 2 200px; /* chrome, safari */
    -moz-columns: 2 200px;    /* firefox */
  }
  .col3 {
    columns: 3 100px;
    -webkit-columns: 3 100px;
    -moz-columns: 3 100px;
  }
</style>


## Project Data-sets

Possible Data Sets and Problems

| Data Sets         | Problem Description                         |
|-------------------|---------------------------------------------|
| Leukemia Data Set | Large-scale Simultaneous Hypothesis Testing |
| Exit Poll Data    | Analyze Associations                        |
| Twitter Data      | Analyze Time-series Trend of Sentiments     |

## Today 

1. This intro will show you how to read the two data-sets and get basic summary. It will also suggest some of the analysis that you can perform.
2. You can use one of the methods taught in class (or try new methods - it's upto you (and your team)). 
3. You do not need to present your work. Only submit a well-written report. 

# Project 1: Multiple Nonparametric Testing: Gene Expression Data

## Project 1: Analysing Genomic Data 

-  Possible Inferential Goals: 

  1. Visualize the data: e.g. compare the baseline expression values between two groups (ALL `golub.cl=0` vs AML `golub.cl=1`)
  2. Carry out Multiple testing. 
  3. We can carry out $p$ simultaneous tests for each of the variables: 

## R packages 

1. 'ALL' package from Bioconductor. 

```{r, echo = T, eval = F}
## try http:// if https:// URLs are not supported
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("ALL")
```

2. 'multtest' package. 
```{r, echo = T, eval = F}
BiocManager::install("multtest")
```

3. (Optional) `Limma' package
```{r, echo = T, eval = F}
BiocManager::install("limma")
```


## Large Scale Testing

- Suppose for the $i^{th}$ variable $x_{i}$ the two group means are $\theta_{i,1}$ and $\theta_{i,2}$.
$$
H_{0i}: \theta_{i,1} = \theta_{i,2} \text{ vs. } H_{1i}: \theta_{i,1} \neq \theta_{i,2}
$$
- If $H_{0i}$ is true, the group means $\bar{x}_{i,1}$ and  $\bar{x}_{i,1}$ should be close. 
- We can do an independent samples t-test for each of the $p$ variables.
- Multiplicity !!

## Example with Simulated Data {.small}

```{r, echo = T}
set.seed(123)
n = 200 ; p1 = 0.1
z1 = rnorm(n*p1, 2, 1); z2 = rnorm(n*(1-p1),0, 1)
z = c(z1,z2)
hist(z, freq = F, ylim = c(0,0.7)); curve(dnorm, add = T)
```

## Testing 

Suppose, $H_0: \mu = 0$ vs. $H_1: \mu \ne 0$ (Simple $Z$-test)
```{r, echo = T}
rawp = 2*(1 - pnorm(abs(z)))
reject.indices <- (rawp < 0.05)
sum(reject.indices)
true.indices = c(rep(1, n*p1), rep(0, n*(1-p1)))

(table(true.indices,reject.indices))
```

## False rejection 

- Naively comparing all $n$ P-values to the significance level $\alpha$ would mean that by purely random chance, $n \times \alpha$ of them will be falsely rejected. 

- Why? 

## False Discoveries 

- Under the $H_0$, p-values are (1-CDF)'s, i.e. each $p_i \sim U(0,1)$, i.e. $P(p_i \le \alpha) = \alpha$. 

- Probability of error = $\alpha$, Probability of not making an error = $1-\alpha$. 
- Probability of not making an error in $m$ tests: $(1-\alpha)^m$. 

- P(Making at least 1 error in $m$ tests) = $1-(1-\alpha)^m$.

## How does this grow? 

```{r, echo = T}
m = (0:100)
alpha = 0.05 
FWEP = 1 - (1-alpha)^m 
plot(m,FWEP,type = "l", ylab = "P(at least 1 false positive)")
```


## Example from T-cell lymphoma {.build}

```{r,echo=TRUE, message=FALSE, warning=FALSE, cache=T}
## required for gene expression data classification example
require(ALL)
data(ALL)
dim(ALL)
```


## Simplifying features 

We are going to use the first three features. 

```{r, echo=TRUE}
resp <- gsub("B[0-9]", "B", ALL$BT) 
## B-cell tumors of type B, B1,B2, T, T1, T2 
resp <- factor(gsub("T[0-9]", "T", resp))
xmat <- t(exprs(ALL))
mydata <- data.frame(y = resp,x1 = xmat[,1],x2=xmat[,2],x3=xmat[,3])
head(mydata,n=3)
```

## Further Analysis 

-  Let's look at the results of molecular biology testing for the 128 samples:

```{r, echo = T}
table(ALL$mol.biol)
```

- Not all levels are frequent ! 

## Filter 

Ignoring the samples which came back negative on this test (NEG), most have been classified as (BCR/ABL) or (ALL1/AF4).

For the purposes of this example, we are only interested in these two subgroups, so we will create a filtered version of the dataset using this as a selection criteria:

```{r, echo = T}
eset <- ALL[, ALL$mol.biol %in% c("BCR/ABL", "ALL1/AF4")]
dim(eset)
```


## How do we analyze this data?

- We have the expression levels 12,625 genes for 47 samples. 
- We also have a factor `ALL$mol.biol` that has two levels: BCR/ABL and ALL1/AF4. 
- We can ask for which genes, the gene expression values differ between these two subgroups? 
- Two sample tests !

## Simple test 

- One idea would be use a two sample t-test for equality of group mean for each of the 12,625 genes. 
- The `mt.teststat` function from the `multtest` library does this for you. 

```{r, echo = T, cache=T}
require(multtest)
all.mat = exprs(eset)
all.cl <- factor(as.character(eset$mol.biol))
teststat = mt.teststat(all.mat,all.cl,test="t")
```

- mt.teststat {multtest}: **Computing test statistics for each row of a data frame**

## Why t-test? 

- These functions provide a convenient way to compute test statistics, e.g., two-sample Welch t-statistics, **Wilcoxon statistics**, F-statistics, paired t-statistics, block F-statistics, for each row of a data frame.
- Should we use a t-test or a different test? 
- How do you know? 

## Visualize {.small}

```{r, echo = F}
par(mfrow=c(1,2))
qqnorm(teststat, ylim = c(-5,5))
qqline(teststat)
hist(teststat, breaks = 30, col = "red", freq = F, xlim = c(-5,5), ylim = c(0,0.5))
curve(dnorm(x), lty = 2, lwd = 2, add=TRUE)
curve(dnorm(x, mean = mean(teststat), sd = sd(teststat)), lty = 3, lwd = 2, add=TRUE)
```

- Histogram and N(0,1) density different on the tails - a few interesting genes?


## Multiple Testing Issues 

- We have a large number of tests: 12,625. If we use standard hypothesis testing at a 5% significance level, 5% of all tests will be falsely rejected (type 1 error) just by pure chance. 

- We need some kind of multiplicity control. 

- The most stringent is Bonferroni: Divide each $\alpha$ by the total number of tests $p = 12,625$. 

## Bonferroni 

- Bonferroni's correction controls for the familywise error rate (FWER) instead of each $\alpha$. 
$$
FWER = P(\text{at least one false rejection}) \le \alpha 
$$

- Bonferroni leads to a stringent test, since $\alpha/p$ could be very small if we are carrying out a large number of $p$ tests simultaneously. 
- In R, we can apply the `p.adjust` function for this task. 

- `p.adjust` also has other useful methods such as "Benjamini-Hochberg False Discovery Rate control procedure".

## Bonferroni 

```{r, echo = T}
rawp = 2 * (1 - pnorm(abs(teststat)))
selected  <- p.adjust(rawp, method = "bonferroni") <0.05
esetSel <- eset [selected, ]
sum(selected)
```

- Bonferroni's correction leads to rejection of `r sum(selected)
` tests - these genes significantly differ between two groups

## Visualize the outcomes

```{r, echo = T}
heatmap(exprs(esetSel))
```

## Better heatmap {.smaller}

```{r, echo = T}
library(RColorBrewer)
hmcol<-brewer.pal(11,"RdBu")
heatmap(exprs(esetSel), col = hmcol, xlab = "Significant Genes", ylab =  "Samples")
```

## Bonferroni 

- $M$ hypothesis tests: $H_{0m}$ vs. $H_{1m}$ for $m = 1, \ldots, M$. 
- Let $p_1, \ldots, p_M$ be the p-values for these $M$ tests. 
- In our case $M = p$ (no. of genes)
- Bonferroni method: 
$$
\text{Reject null hypothesis } H_{0m} \text{ if } p_m \le \frac{\alpha}{M}
$$

- Outcome: The probability of falsely rejecting any null hypothesis is less than or equal to $\alpha$. 

## Benjamini-Hochberg {.smaller}

- Let $M_0$ be the number of null hypotheses that are true, $M_0 = M - M_1$. 

|           |$H_0$ acc |	$H_0$ rej | Total |
|-----------|----------|------------|-------|
|$H_0$ true |	U        | V          | $M_0$ |
|$H_0$ false|	T        | S          | $M_1$ |
|Total      |	M-R      | R          | $M$   |

Define the false discovery proportion (FDP): 
$$
FDP = \begin{cases} 
V/R \text{ if } R > 0 \\
0 \text { otherwise}
\end{cases}
$$

## Benjamini-Hochberg {.smaller}

- $M$ hypothesis tests We order the p-values in increasing order.
$p_{(1)} \le \ldots \le p_{(M)}$. 
- *Benjamini-Hochberg Method* 
    1.  For a given $\alpha$ find the largest $k$ such that
$$
p_{(k)} \le k \frac{\alpha}{M}
$$
    2.  Then reject all $H_{0m}$ for $m = 1, \ldots, k$.
-  *Theorem* : 
$$
FDR = E(FDP) \le \frac{M_0}{M}\alpha \le \alpha
$$
-  *Outcome*: For a given significance level $\alpha$, the Benjamini Hochberg method bounds the false discovery rate.

## Benjamini-Hochberg

```{r, echo = T}
rawp = 2 * (1 - pnorm(abs(teststat)))
selected  <- p.adjust(rawp, method = "BH") <0.05
esetSel <- eset [selected, ]
sum(selected)
```

- Benjamini-Hochberg method leads to rejection of `r sum(selected)
` tests - less stringent than Bonferroni. 

## Benjamini-Hochberg's heatmap {.smaller}

```{r, echo = T}
library(RColorBrewer)
hmcol<-brewer.pal(11,"RdBu")
heatmap(exprs(esetSel), col = hmcol, xlab = "Significant Genes", ylab =  "Samples")
```

## Many different ways

- There are many different ways of doing the same analysis - we usually pick the one that gives us a reasonably accurate and yet meaningful answer. 

- For example, in a Statistical genetics study, your collaborator (a geneticist) might have some prior biological knowledge about which genes should be different, and that provides a way of checking validity. 

## Regression Approach {.build}

- The variable `ALL$mol.biol` has two levels: BCR/ABL and ALL1/AF4. So far, we have tested the difference between gene expression values between these two groups. 

- We can think of the levels of `ALL$mol.biol` as a binary response variable, and use the gene expression values as a design matrix $X$ to predict the levels. 


## Empirical Bayes (Advanced)

- We can use the `lmFit` function (from the `limma` package) to fit a linear model for each gene given a series of arrays.

- The fitted model object is further processed by the `eBayes` function to produce empirical Bayes test statistics and P-values for each gene. 

```{r, echo = T, warning = F, message = F}
library(limma)
f <- factor(as.character(eset$mol.biol))
design <- model.matrix(~f)
fit <- eBayes(lmFit(eset,design))
```

## P-values {.smaller}

```{r, echo = T}
topTable(fit, coef=2)
```

The leftmost numbers are row indices, `logFC` is the log ratio of expression, `AveExpr` is the log average expression, `t` the moderated t-statistic, and `B` is the log odds of differential expression.

## Selection 

Next, we select those genes that have adjusted p-values below 0.05, using a Benjamini-Hochberg method to select a small number of genes.

```{r, echo = T}
selected  <- p.adjust(fit$p.value[, 2], method = "BH") <0.05
esetSel <- eset [selected, ]
sum(selected)
```

## Heatmap 

The variable esetSel has data on (only) 749 genes for all 47 samples . We can easily produce a heatmap as follows:

```{r, echo = T}
heatmap(exprs(esetSel))
```

## Selection 

We could be very stringent - use Bonferroni! 

```{r, echo = T}
selected  <- p.adjust(fit$p.value[, 2], method = "bonferroni") <0.05
esetSel <- eset [selected, ]
sum(selected)
```

## Heatmap 

The variable `esetSel` has data on (only) 165 genes for all 47 samples . We can easily produce a heatmap as follows:

```{r, echo = T}
heatmap(exprs(esetSel))
```


# Project 2: Test of Association for Political Data


## Project 2: Contingency tables

- Some of the best examples of contingency tables come from Political data analysis. 

- Example: Analyzing Exit Poll Data from CNN. Total number of respondents = 24537.

|Party   | 18-24	| 25-29	| 30-39	| 40-49	| 50-64	| 65 and older |
|--------|--------|-------|-------|-------|-------|--------------|
|Clinton | 56%	  | 53%  	| 51% 	| 46% 	| 44%  	| 45%          |
|Trump   |	35%	  | 39%   | 40% 	| 50%	  | 53%	  | 53%          |


## Test for association {.smaller}

```{r, echo = T, fig.height= 4}
clinton = c(1374,1170,2127,2145,3239,1656)
trump = c(859,861,1669,2331,3901,1951)
elect16= rbind(clinton,trump)
dimnames(elect16) = list(candidate = c("clinton","trump"), 
                         agegp = c("18-24","25-29","30-39",
                                   "40-49","50-64",">65"))
barplot(elect16, beside=T, legend=T)
```

## Chi-square test 

```{r, echo = T}
chisq.test(elect16)
```
- We can reject the null hypothesis that the proportions are not equal across different age groups. 


## Effect of Gender? 

- We can also look at the effect of Gender!
- The same CNN exit poll data : 24537 respondents. 

|Party |clinton |	trump| others|
|------|--------|------|-------|
| male |	41%  	| 53%	 | 6%    |
|female|	54%	  | 42%  |  4%   |

## Use R {.smaller}

```{r, echo = T, fig.height=4}
gender <- matrix(c(4829,6242,707,6890,5359,510), byrow = T, ncol = 3)
dimnames(gender) = list(gender = c("male","female"), 
                        candidate = c("clinton","trump","others"))
barplot(t(gender), beside=T, legend=T)
```

## Chi-square test of association 

```{r, echo = TRUE}
gender <- matrix(c(4829,6242,707,6890,5359,510), byrow = T, ncol = 3)
dimnames(gender) = list(gender = c("male","female"), 
                        candidate = c("clinton","trump","others"))
prop.table(gender, 1)
chisq.test(gender)
```